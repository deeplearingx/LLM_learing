import os
import time
import requests
from tqdm import tqdm
from requests.exceptions import RequestException

# ==========================
# é…ç½®åŒºåŸŸ
# ==========================

# âœ… æ­£ç¡®çš„é•œåƒå‰ç¼€ï¼šç”¨ resolveï¼Œè€Œä¸æ˜¯ tree
#æ”¾å…¥ä¸‹è½½çš„é“¾æ¥
BASE_URL = "https://hf-mirror.com/datasets/jingyaogong/minimind-v_dataset/resolve/main"

# è¦ä¸‹è½½çš„æ–‡ä»¶åˆ—è¡¨
FILES = [
    "sft_data.jsonl",
    "sft_images.zip",
]

# æœ¬åœ°ä¿å­˜ç›®å½•
SAVE_DIR = "/root/autodl-tmp/ai_learing/datasets/SFT_images"

# é‡è¯•è®¾ç½®
MAX_RETRIES = 5
RETRY_BASE_WAIT = 5


def download_file(url: str, save_path: str) -> bool:
    """æ”¯æŒæ–­ç‚¹ç»­ä¼  + é‡è¯•"""

    temp_size = 0
    if os.path.exists(save_path):
        temp_size = os.path.getsize(save_path)

    print(f"\nå¼€å§‹ä¸‹è½½: {url}")
    print(f"ğŸ‘‰ å·²æœ‰ {temp_size} å­—èŠ‚ï¼Œå°†å°è¯•æ–­ç‚¹ç»­ä¼ ...")

    headers = {"Range": f"bytes={temp_size}-"} if temp_size > 0 else {}

    for attempt in range(1, MAX_RETRIES + 1):
        try:
            resp = requests.get(url, stream=True, headers=headers, timeout=60)

            if resp.status_code in (200, 206):
                total_size = resp.headers.get("content-length")
                total_size = int(total_size) if total_size is not None else 0
                total_to_download = temp_size + total_size
                mode = "ab" if temp_size > 0 else "wb"

                with open(save_path, mode) as f, tqdm(
                    total=total_to_download,
                    initial=temp_size,
                    unit="B",
                    unit_scale=True,
                    desc=os.path.basename(save_path),
                ) as bar:
                    for chunk in resp.iter_content(chunk_size=1024 * 1024):
                        if chunk:
                            f.write(chunk)
                            bar.update(len(chunk))

                print(f"âœ… ä¸‹è½½å®Œæˆ: {save_path}")
                return True

            elif 500 <= resp.status_code < 600:
                wait_time = RETRY_BASE_WAIT * attempt
                print(
                    f"âš ï¸ æœåŠ¡å™¨å¼‚å¸¸ HTTP {resp.status_code}, "
                    f"ç¬¬ {attempt}/{MAX_RETRIES} æ¬¡é‡è¯•ï¼Œ{wait_time} ç§’åé‡è¯•..."
                )
                time.sleep(wait_time)
                continue

            else:
                print(f"âŒ æ— æ³•ä¸‹è½½ï¼ˆHTTP {resp.status_code}ï¼‰ï¼Œåœæ­¢é‡è¯•")
                return False

        except RequestException as e:
            wait_time = RETRY_BASE_WAIT * attempt
            print(
                f"âš ï¸ ç½‘ç»œå¼‚å¸¸: {e}, "
                f"ç¬¬ {attempt}/{MAX_RETRIES} æ¬¡é‡è¯•ï¼Œ{wait_time} ç§’åé‡è¯•..."
            )
            time.sleep(wait_time)

    print(f"âŒ å¤šæ¬¡é‡è¯•å¤±è´¥: {url}")
    return False


if __name__ == "__main__":
    os.makedirs(SAVE_DIR, exist_ok=True)

    all_ok = True
    for fname in FILES:
        # âœ… è¿™é‡Œä¸€å®šè¦åŠ  '/'ï¼Œå¦åˆ™ä¼šå˜æˆ mainsft_xxx è¿™ç§é”™è¯¯
        url = f"{BASE_URL}/{fname}"
        save_path = os.path.join(SAVE_DIR, fname)
        ok = download_file(url, save_path)
        all_ok = all_ok and ok

    if all_ok:
        print("\nğŸ‰ æ‰€æœ‰æ–‡ä»¶æˆåŠŸä¸‹è½½ï¼")
    else:
        print("\nâš ï¸ æœ‰æ–‡ä»¶ä¸‹è½½å¤±è´¥ï¼Œè¯·æŸ¥çœ‹ä¸Šæ–¹æ—¥å¿—ã€‚")
